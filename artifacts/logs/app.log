2025-01-05 00:40:03,490 - INFO - Checkpoint successfully saved at 20250105-004003_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 00:40:03,492 - INFO - Successfully built the recommender using AlternatingLeastSquares
2025-01-05 03:54:16,281 - WARNING - The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 03:55:54,308 - WARNING - The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 03:58:29,485 - WARNING - The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 03:58:29,485 - INFO - Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 03:58:29,485 - INFO - Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 03:58:29,485 - INFO - Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 03:58:29,500 - INFO - Checkpoint ./artifacts/checkpoints/als/1000000/20250105-004003_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 03:59:07,342 - INFO - All factors and biases are already provided, so no initialization is needed.
2025-01-05 04:02:30,354 - INFO - Checkpoint successfully saved at 20250105-040230_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 04:02:30,354 - INFO - Successfully built the recommender using AlternatingLeastSquares
2025-01-05 04:11:02,437 - WARNING - The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 04:11:09,418 - WARNING - The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 04:11:09,419 - INFO - Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 04:11:09,689 - INFO - Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 04:11:09,691 - INFO - Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 04:11:09,696 - INFO - Checkpoint ./artifacts/checkpoints/als/1000000/20250105-040230_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 04:11:09,697 - INFO - All factors and biases are already provided, so no initialization is needed.
2025-01-05 04:12:11,279 - INFO - Checkpoint successfully saved at 20250105-041211_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 04:12:11,280 - INFO - Successfully built the recommender using AlternatingLeastSquares
2025-01-05 04:14:23,410 - WARNING - The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 04:14:30,005 - WARNING - The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 04:14:30,005 - INFO - Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 04:14:30,005 - INFO - Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 04:14:30,006 - INFO - Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 04:14:30,008 - INFO - Checkpoint ./artifacts/checkpoints/als/1000000/20250105-041211_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 04:14:30,009 - INFO - All factors and biases are already provided, so no initialization is needed.
2025-01-05 04:15:36,605 - INFO - Checkpoint successfully saved at 20250105-041536_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 04:15:36,606 - INFO - Successfully built the recommender using AlternatingLeastSquares
2025-01-05 04:16:00,029 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 04:16:06,076 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 04:16:06,076 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 04:16:06,077 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 04:16:06,077 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 04:16:06,080 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-041536_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 04:16:06,081 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-05 04:17:08,006 [INFO] Checkpoint successfully saved at 20250105-041707_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 04:17:08,006 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-05 15:17:48,749 - WARNING - The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 15:17:56,661 - WARNING - The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 15:17:56,661 - INFO - Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 15:17:56,744 - INFO - Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 15:17:56,746 - INFO - Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 15:17:56,775 - INFO - Checkpoint ./artifacts/checkpoints/als/1000000/20250105-041707_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 15:17:56,776 - INFO - All factors and biases are already provided, so no initialization is needed.
2025-01-05 15:19:12,991 - INFO - Checkpoint successfully saved at 20250105-151912_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 15:19:12,992 - INFO - Successfully built the recommender using AlternatingLeastSquares
2025-01-05 15:22:09,778 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 15:22:21,009 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 15:22:21,010 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 15:41:04,905 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 15:41:12,927 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 15:41:12,928 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 15:45:55,933 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 15:46:03,264 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 15:46:03,264 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 15:46:24,790 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 15:46:32,245 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 15:46:32,247 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 15:46:34,427 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 15:46:34,429 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 15:46:34,450 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-151912_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 15:46:34,451 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-05 15:47:47,240 [INFO] Checkpoint successfully saved at 20250105-154747_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 15:47:47,241 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-05 16:05:52,101 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 16:05:59,007 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 16:05:59,008 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 16:50:16,531 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 16:50:23,146 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 16:50:23,147 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 16:50:26,578 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 16:50:26,580 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 16:50:26,599 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-154747_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 16:50:26,601 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-05 16:52:01,257 [INFO] Checkpoint successfully saved at 20250105-165201_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 16:52:01,258 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-05 16:53:00,056 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 16:53:07,269 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 16:53:07,270 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 16:53:11,192 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 16:53:11,194 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 16:53:11,198 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-165201_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 16:53:11,199 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-05 16:54:17,945 [INFO] Checkpoint successfully saved at 20250105-165417_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 16:54:17,946 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-05 16:54:18,626 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-05 16:54:25,258 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-05 16:54:25,259 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-05 16:54:28,290 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-05 16:54:28,292 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-05 16:54:28,296 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-165417_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-05 16:54:28,298 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-05 16:55:41,258 [INFO] Checkpoint successfully saved at 20250105-165541_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-05 16:55:41,259 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 00:49:41,413 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 00:49:50,364 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 00:49:50,365 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 01:28:04,436 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 01:28:12,096 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 01:28:12,096 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 01:28:16,497 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 01:28:16,500 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 01:28:16,521 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-165541_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 02:57:15,011 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 02:57:28,521 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 02:57:28,523 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 02:57:35,532 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 02:57:35,538 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 02:57:35,560 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-165541_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:07:41,467 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:08:24,229 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:08:24,232 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:08:37,353 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:08:37,359 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:08:37,391 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-165541_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:18:16,379 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:18:22,911 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:18:22,912 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:18:27,484 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:18:27,486 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:18:27,504 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-165541_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:39:08,100 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:39:15,289 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:39:15,291 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:39:19,576 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:39:19,579 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:39:19,596 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250105-165541_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:39:19,598 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 03:40:23,804 [INFO] Checkpoint successfully saved at 20250106-034023_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 03:40:23,805 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 03:41:18,001 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:41:24,190 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:41:24,191 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:41:28,226 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:41:28,228 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:41:28,233 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-034023_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:41:28,235 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 03:42:55,205 [INFO] Checkpoint successfully saved at 20250106-034255_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 03:42:55,210 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 03:43:40,669 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:43:46,942 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:43:46,943 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:43:51,098 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:43:51,099 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:43:51,119 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-034255_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:43:51,120 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 03:45:04,575 [INFO] Checkpoint successfully saved at 20250106-034504_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 03:45:04,576 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 03:46:19,076 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:46:26,203 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:46:33,008 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:46:33,009 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:46:40,877 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:46:47,199 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:46:47,200 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:46:51,122 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:46:51,124 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:46:51,127 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-034504_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:46:51,128 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 03:47:52,519 [INFO] Checkpoint successfully saved at 20250106-034752_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 03:47:52,521 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 03:47:53,289 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:48:01,437 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:48:01,438 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:48:06,107 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:48:06,112 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:48:06,118 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-034752_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:48:06,120 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 03:49:19,845 [INFO] Checkpoint successfully saved at 20250106-034919_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 03:49:19,846 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 03:50:51,077 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:50:59,179 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:50:59,180 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:51:04,942 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:51:04,944 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:51:04,948 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-034919_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:51:04,951 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 03:52:11,428 [INFO] Checkpoint successfully saved at 20250106-035211_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 03:52:11,431 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 03:54:04,555 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 03:54:12,152 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 03:54:12,153 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 03:54:16,404 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 03:54:16,408 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 03:54:16,414 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-035211_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 03:54:16,415 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 03:55:18,775 [INFO] Checkpoint successfully saved at 20250106-035518_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 03:55:18,776 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 18:38:16,234 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 18:38:25,424 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 18:38:25,425 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 18:38:25,878 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 18:38:25,878 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 18:38:25,895 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-035518_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 18:38:25,895 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 18:39:41,481 [INFO] Checkpoint successfully saved at 20250106-183941_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 18:39:41,481 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 19:17:49,429 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 19:17:58,928 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 19:17:58,929 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 19:17:59,405 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 19:17:59,405 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 19:17:59,406 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-183941_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 19:17:59,407 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 19:18:56,513 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 19:19:05,449 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 19:19:05,449 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 19:19:05,881 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 19:19:05,882 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 19:19:05,882 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 19:19:42,938 [INFO] Checkpoint successfully saved at 20250106-191942_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-06 19:19:42,938 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 19:23:05,484 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 19:23:14,619 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 19:23:14,619 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 19:23:15,055 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 19:23:15,055 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 19:23:15,055 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 19:23:51,482 [INFO] Checkpoint successfully saved at 20250106-192351_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-06 19:23:51,482 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 20:02:41,624 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 20:02:50,768 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 20:02:50,768 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 20:02:51,209 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 20:02:51,209 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 20:02:51,209 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 20:03:34,285 [INFO] Checkpoint successfully saved at 20250106-200334_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-06 20:03:34,285 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 20:06:24,164 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 20:06:33,325 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 20:06:33,325 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 20:06:33,918 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 20:06:33,919 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 20:06:33,919 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 20:08:19,077 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 20:08:28,218 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 20:08:28,219 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 20:08:28,675 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 20:08:28,675 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 20:08:28,675 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 20:13:14,223 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 20:13:23,019 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 20:13:23,019 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 20:13:23,457 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 20:13:23,457 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 20:13:23,457 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 20:14:05,660 [INFO] Checkpoint successfully saved at 20250106-201405_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-06 20:14:05,660 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 20:24:34,863 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 20:24:44,577 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 20:24:44,577 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 20:24:45,222 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 20:24:45,222 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 20:24:45,222 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 20:25:23,314 [INFO] Checkpoint successfully saved at 20250106-202523_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-06 20:25:23,314 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 20:28:18,685 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 20:28:28,272 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 20:28:28,272 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 20:28:28,842 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 20:28:28,843 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 20:28:28,843 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-06 20:29:05,252 [INFO] Checkpoint successfully saved at 20250106-202905_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-06 20:29:05,252 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 23:06:34,954 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 23:06:42,355 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 23:06:42,357 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 23:06:46,442 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 23:06:46,444 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 23:06:46,469 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20241231-021927_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 23:06:46,471 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 23:07:46,679 [INFO] Checkpoint successfully saved at 20250106-230746_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 23:07:46,680 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 23:42:53,793 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 23:43:03,332 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 23:43:03,333 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-06 23:43:13,694 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-06 23:43:13,694 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-06 23:43:13,696 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250106-230746_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10.pkl loaded with success
2025-01-06 23:43:13,696 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-06 23:43:13,696 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' is already greater or equal to the final number of epochs wanted (4). Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-06 23:43:13,709 [INFO] Checkpoint successfully saved at 20250106-234313_lambda0.1_gamma0.01_tau1_n_epochs4_n_factors10
2025-01-06 23:43:13,709 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-06 23:50:28,120 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-06 23:50:37,503 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-06 23:50:37,503 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:02:30,789 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:02:37,844 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:02:37,845 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:02:55,992 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:03:03,337 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:03:03,338 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:03:04,198 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:03:04,203 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:03:04,204 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 00:03:35,921 [INFO] Checkpoint successfully saved at 20250107-000335_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:03:35,923 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:04:04,115 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:04:10,845 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:04:10,846 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:04:11,671 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:04:11,674 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:04:11,676 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-000335_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:04:11,678 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:04:42,285 [INFO] Checkpoint successfully saved at 20250107-000442_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:04:42,286 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:06:02,763 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:06:13,293 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:06:13,293 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:07:16,226 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:07:21,961 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:07:21,961 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:07:22,283 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:07:22,283 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:07:22,284 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-000442_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:07:22,285 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:07:53,807 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' is already greater or equal to the final number of epochs wanted (2). Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 00:07:56,685 [INFO] Checkpoint successfully saved at 20250107-000756_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:07:56,685 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:08:12,554 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:08:18,193 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:08:18,193 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:08:18,521 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:08:18,521 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:08:18,522 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-000756_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:08:18,523 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:08:18,523 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' is already greater or equal to the final number of epochs wanted (2). Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 00:08:18,535 [INFO] Checkpoint successfully saved at 20250107-000818_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:08:18,535 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:09:40,098 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:09:45,806 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:09:45,806 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:09:46,130 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:09:46,130 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:09:46,131 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-000818_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:09:46,131 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:09:46,131 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (2) is already greater or equal to the final number of epochs wanted which is 2. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 00:09:46,136 [INFO] Checkpoint successfully saved at 20250107-000946_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:09:46,136 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:09:56,371 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:10:02,965 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:10:02,965 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:10:03,812 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:10:03,813 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:10:03,817 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-000946_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:10:03,819 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:10:34,513 [INFO] Checkpoint successfully saved at 20250107-001034_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:10:34,514 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:10:56,524 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:11:03,390 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:11:03,391 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:11:04,542 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:11:04,549 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:11:04,553 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-001034_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:11:04,554 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:11:04,555 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (2) is already greater or equal to the final number of epochs wanted which is 2. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 00:11:04,571 [INFO] Checkpoint successfully saved at 20250107-001104_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:11:04,572 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:11:33,033 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:11:39,262 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:11:39,264 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:11:40,074 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:11:40,077 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:11:40,081 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-001104_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:11:40,082 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:11:40,083 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (2) is already greater or equal to the final number of epochs wanted which is 2. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 00:11:40,096 [INFO] Checkpoint successfully saved at 20250107-001140_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:11:40,097 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:11:43,922 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:11:50,103 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:11:50,104 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:11:50,942 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:11:50,944 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:11:50,947 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-001140_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:11:50,948 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:11:50,949 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (2) is already greater or equal to the final number of epochs wanted which is 2. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 00:11:50,958 [INFO] Checkpoint successfully saved at 20250107-001150_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:11:50,961 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:11:54,319 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 00:12:00,530 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 00:12:00,531 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 00:12:01,337 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 00:12:01,340 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 00:12:01,345 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-001150_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 00:12:01,347 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 00:12:01,348 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (2) is already greater or equal to the final number of epochs wanted which is 2. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 00:12:01,360 [INFO] Checkpoint successfully saved at 20250107-001201_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10
2025-01-07 00:12:01,361 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 00:57:02,309 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 01:00:30,767 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 01:00:31,339 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 01:00:31,340 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 01:00:31,421 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000000/20241231-052949_lambda0.1_gamma0.01_tau1_n_epochs20_n_factors10.pkl loaded with success
2025-01-07 01:00:31,422 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 01:00:31,422 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 01:00:31,470 [INFO] Checkpoint successfully saved at 20250107-010031_lambda0.1_gamma0.01_tau1_n_epochs20_n_factors10
2025-01-07 01:00:31,471 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 01:19:47,293 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 01:23:28,110 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 01:23:28,608 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 01:23:28,608 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 01:23:28,608 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 01:23:28,681 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (30) is already greater or equal to the final number of epochs wanted which is 30. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 01:23:28,721 [INFO] Checkpoint successfully saved at 20250107-012328_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10
2025-01-07 01:23:28,721 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 01:53:27,787 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 01:56:48,811 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 01:56:49,210 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 01:56:49,210 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 01:56:49,250 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000000/20250107-012328_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10.pkl loaded with success
2025-01-07 01:56:49,252 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 01:56:49,252 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (30) is already greater or equal to the final number of epochs wanted which is 30. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 01:56:49,314 [INFO] Checkpoint successfully saved at 20250107-015649_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10
2025-01-07 01:56:49,314 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 02:02:49,658 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 02:05:46,630 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 02:05:47,019 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 02:05:47,019 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 02:05:47,068 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000000/20250107-015649_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10.pkl loaded with success
2025-01-07 02:05:47,069 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 02:05:47,069 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (30) is already greater or equal to the final number of epochs wanted which is 30. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 02:05:47,121 [INFO] Checkpoint successfully saved at 20250107-020547_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10
2025-01-07 02:05:47,122 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 03:02:40,040 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 03:02:45,985 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 03:02:45,985 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 03:02:46,340 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 03:02:46,340 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 03:02:46,346 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-001201_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 03:02:46,347 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 03:04:25,653 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 03:04:32,421 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 03:04:32,422 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 03:04:49,654 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 03:05:10,872 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 03:05:10,872 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 03:05:11,616 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 03:05:11,616 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 03:05:11,618 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-001201_lambda0.1_gamma0.01_tau1_n_epochs2_n_factors10.pkl loaded with success
2025-01-07 03:06:25,944 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 03:06:46,964 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 03:06:46,965 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 03:06:47,712 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 03:06:47,712 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 03:08:28,268 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 03:08:33,870 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 03:08:33,870 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 03:08:34,197 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 03:08:34,197 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 03:08:34,197 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 03:16:19,560 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-07 03:16:19,569 [INFO] Checkpoint successfully saved at 20250107-031619_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10
2025-01-07 03:16:19,570 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 03:32:36,819 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 03:36:32,687 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 03:36:33,568 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 03:36:33,569 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 03:36:33,570 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 03:36:34,015 [INFO] Epochs count to train for 30, entering the training loop now
2025-01-07 07:22:15,503 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-07 07:22:15,610 [INFO] Checkpoint successfully saved at 20250107-072215_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10
2025-01-07 07:22:15,611 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 07:31:57,659 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.
2025-01-07 07:34:51,627 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 07:34:51,959 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 07:34:51,960 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 07:34:51,960 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 07:34:52,031 [INFO] Epochs count to train for 30, entering the training loop now
2025-01-07 11:37:12,613 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-07 11:37:12,681 [INFO] Checkpoint successfully saved at 20250107-113712_lambda0.1_gamma0.01_tau0.1_n_epochs30_n_factors10
2025-01-07 11:37:12,681 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 14:26:35,998 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 14:26:42,268 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 14:26:42,269 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 14:26:43,172 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 14:26:43,174 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 14:26:43,200 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-031619_lambda0.1_gamma0.01_tau1_n_epochs30_n_factors10.pkl loaded with success
2025-01-07 14:26:43,201 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 14:26:43,202 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (30) is already greater or equal to the final number of epochs wanted which is 30. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 14:26:43,203 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 15:18:25,554 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 15:25:03,175 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 15:25:03,932 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 15:25:03,932 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 15:25:03,933 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 15:25:04,157 [INFO] Epochs count to train for 30, entering the training loop now
2025-01-07 16:56:34,206 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 17:02:03,136 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 17:02:05,253 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 17:02:05,254 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 17:02:05,554 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000000/20250107-113712_lambda0.1_gamma0.01_tau0.1_n_epochs30_n_factors10.pkl loaded with success
2025-01-07 17:02:05,629 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-07 17:02:05,629 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (30) is already greater or equal to the final number of epochs wanted which is 30. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-07 17:02:05,630 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 17:04:43,302 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 17:10:30,602 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 17:10:31,764 [INFO] Starting the build of the recommender using AlternatingLeastSquares...
2025-01-07 17:10:31,765 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 17:10:31,766 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 17:10:32,091 [INFO] Epochs count to train for 30, entering the training loop now
2025-01-07 19:09:00,832 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 19:09:12,876 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 19:09:12,964 [WARNING] The limit of lines (.i.e 1000) to index has been reached. Exiting without loading the rest... 
2025-01-07 19:09:12,964 [INFO] Successfully indexed 1000 lines from ./ml-32m/ratings.csv
2025-01-07 21:17:34,554 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-07 21:17:34,635 [INFO] Checkpoint successfully saved at 20250107-211734_lambda2_gamma0.03_tau0.6_n_epochs30_n_factors10
2025-01-07 21:17:34,636 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 22:21:50,592 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 22:22:29,061 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 22:34:30,196 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 22:34:36,697 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 22:34:36,698 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 22:36:12,023 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 22:36:18,498 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-07 22:36:18,498 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-07 22:36:19,061 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 5, 'hyper_tau': 0.5, 'hyper_gamma': 0.2, 'hyper_n_epochs': 10, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-07 22:36:19,062 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 22:36:19,062 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 22:36:19,076 [INFO] Epochs count to train for 10, entering the training loop now
2025-01-07 22:39:30,351 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-07 22:39:30,358 [INFO] Checkpoint successfully saved at 20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10
2025-01-07 22:39:30,358 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-07 22:45:12,150 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-07 22:49:58,324 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-07 22:49:58,862 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 5, 'hyper_tau': 0.5, 'hyper_gamma': 0.2, 'hyper_n_epochs': 10, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-07 22:49:58,862 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-07 22:49:58,862 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-07 22:49:58,952 [INFO] Epochs count to train for 10, entering the training loop now
2025-01-08 00:50:08,507 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-08 00:50:08,565 [INFO] Checkpoint successfully saved at 20250108-005008_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10
2025-01-08 00:50:08,566 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-08 03:16:12,571 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 03:20:57,253 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 03:20:57,760 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.02, 'hyper_n_epochs': 10, 'hyper_n_factors': 20, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 03:20:57,761 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 03:20:57,761 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-08 03:20:58,021 [INFO] Epochs count to train for 10, entering the training loop now
2025-01-08 03:29:33,098 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 03:31:10,506 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 03:32:46,974 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 03:33:31,469 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 03:33:32,046 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 03:33:32,047 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 03:33:32,047 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-08 03:33:32,304 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-08 03:36:08,806 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 03:36:10,785 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 03:36:10,785 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 03:36:10,786 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-08 03:36:14,673 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-08 03:40:53,089 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 03:40:53,461 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 4, 'hyper_tau': 0.2, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 03:40:53,461 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 03:40:53,462 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-08 03:40:53,530 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-08 06:49:17,083 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-08 06:49:17,144 [INFO] Checkpoint successfully saved at 20250108-064917_lambda4_gamma0.01_tau0.2_n_epochs20_n_factors10
2025-01-08 06:49:17,145 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-08 06:51:46,274 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-08 06:51:46,347 [INFO] Checkpoint successfully saved at 20250108-065146_lambda1_gamma0.1_tau0.1_n_epochs20_n_factors10
2025-01-08 06:51:46,348 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-08 13:44:20,296 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 13:48:58,191 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 13:48:58,623 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 4, 'hyper_tau': 0.2, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 13:48:58,623 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 13:48:58,624 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-08 13:48:58,713 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-08 14:08:07,619 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 14:14:16,346 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 14:14:20,413 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 14:14:20,414 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 14:14:20,414 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-08 14:14:21,627 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-08 22:19:40,437 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 22:19:47,936 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-08 22:19:47,937 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-08 22:27:54,187 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 22:28:01,892 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-08 22:28:01,893 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-08 22:28:36,454 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 22:28:43,632 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-08 22:28:43,633 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-08 22:28:45,019 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 22:28:45,021 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 22:28:45,022 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-08 22:28:45,038 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-08 22:30:04,416 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 22:30:12,715 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-08 22:30:12,716 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-08 22:30:14,094 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 22:30:14,096 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 22:30:14,116 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10.pkl loaded with success
2025-01-08 22:30:14,117 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-08 22:30:14,119 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (10) is already greater or equal to the final number of epochs wanted which is 10. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-08 22:30:14,120 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-08 22:37:24,658 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 22:41:23,270 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 22:41:44,189 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 22:41:44,190 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 22:41:44,232 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000000/20250108-214410_lambda0.1_gamma0.01_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-08 22:41:44,233 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-08 22:41:44,233 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-08 22:41:44,233 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-08 22:55:10,191 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-08 22:59:17,571 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-08 22:59:32,817 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-08 22:59:32,817 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-08 22:59:32,866 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000000/20250108-214410_lambda0.1_gamma0.01_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-08 22:59:32,866 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-08 22:59:32,867 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-08 22:59:32,867 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 01:33:01,095 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 01:33:10,639 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 01:33:10,640 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 01:33:12,597 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 01:33:12,601 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 01:33:12,628 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10.pkl loaded with success
2025-01-09 01:33:12,631 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-09 01:33:12,632 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (10) is already greater or equal to the final number of epochs wanted which is 10. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-09 01:33:12,633 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 01:40:58,300 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 01:41:05,315 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 01:41:05,316 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 01:41:06,659 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 01:41:06,663 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 01:41:06,669 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10.pkl loaded with success
2025-01-09 01:41:06,671 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-09 01:41:06,673 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (10) is already greater or equal to the final number of epochs wanted which is 10. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-09 01:41:06,675 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 01:45:09,870 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 01:45:19,876 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 01:45:19,877 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 01:45:21,763 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 01:45:21,766 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 01:45:21,771 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10.pkl loaded with success
2025-01-09 01:45:21,772 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-09 01:45:21,775 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (10) is already greater or equal to the final number of epochs wanted which is 10. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-09 01:45:21,778 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 01:46:46,572 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 01:46:53,984 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 01:46:53,984 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 01:46:55,301 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 01:46:55,303 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 01:46:55,328 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10.pkl loaded with success
2025-01-09 01:46:55,330 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-09 01:46:55,331 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (10) is already greater or equal to the final number of epochs wanted which is 10. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-09 01:46:55,332 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 02:49:07,681 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 02:49:14,347 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 02:49:14,349 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 02:50:32,665 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 02:50:41,239 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 02:50:41,240 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 02:50:43,032 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 02:50:43,034 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 02:50:43,059 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10.pkl loaded with success
2025-01-09 02:50:43,061 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-09 02:50:43,062 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (10) is already greater or equal to the final number of epochs wanted which is 10. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-09 02:50:43,063 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 02:52:37,333 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 02:52:44,887 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 02:52:44,888 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 02:52:46,161 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 02:52:46,163 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 02:52:46,167 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250107-223930_lambda5_gamma0.2_tau0.5_n_epochs10_n_factors10.pkl loaded with success
2025-01-09 02:52:46,168 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-09 02:52:46,170 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (10) is already greater or equal to the final number of epochs wanted which is 10. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-09 02:52:46,175 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 17:20:07,124 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:20:18,348 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:20:18,349 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:20:18,846 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.5, 'hyper_tau': 0.4, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:20:18,846 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:20:18,846 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:20:18,857 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:25:15,356 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:25:24,271 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:25:24,272 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:26:05,208 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:26:14,325 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:26:14,325 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:26:15,771 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:26:35,783 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:26:35,784 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:26:36,551 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.5, 'hyper_tau': 0.4, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:26:36,552 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:27:19,108 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:27:27,357 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:31:15,890 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:31:47,163 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:31:56,068 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:31:56,068 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:31:56,408 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.5, 'hyper_tau': 0.4, 'hyper_gamma': 0.01, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:31:56,408 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:31:56,408 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:31:56,416 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:36:32,343 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-09 17:36:32,352 [INFO] Checkpoint successfully saved at 20250109-173632_lambda0.5_gamma0.01_tau0.4_n_epochs20_n_factors10
2025-01-09 17:36:32,353 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 17:38:46,554 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:38:53,028 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:38:53,029 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:38:53,382 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 1, 'hyper_tau': 0.4, 'hyper_gamma': 0.04, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:38:53,382 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:38:53,383 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:38:53,390 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:44:04,045 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-09 17:44:04,053 [INFO] Checkpoint successfully saved at 20250109-174404_lambda1_gamma0.04_tau0.4_n_epochs20_n_factors10
2025-01-09 17:44:04,053 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 17:45:56,914 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:46:03,131 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:46:03,131 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:46:03,478 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.5, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:46:03,479 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:46:03,479 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:46:03,486 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:50:36,616 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-09 17:50:36,623 [INFO] Checkpoint successfully saved at 20250109-175036_lambda0.5_gamma0.1_tau0.1_n_epochs20_n_factors10
2025-01-09 17:50:36,624 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 17:51:48,707 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:51:54,917 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:51:54,917 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:51:55,265 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 4, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:51:55,265 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:51:55,265 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:51:55,272 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:53:04,103 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:53:11,229 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:53:11,229 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:53:11,583 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:53:11,583 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:53:11,583 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:53:11,591 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:54:30,700 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 17:54:36,842 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-09 17:54:36,842 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-09 17:54:37,194 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 17:54:37,194 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 17:54:37,194 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 17:54:37,203 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 17:59:20,762 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-09 17:59:20,770 [INFO] Checkpoint successfully saved at 20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10
2025-01-09 17:59:20,770 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-09 17:59:35,555 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-09 18:03:00,019 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-09 18:03:00,410 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-09 18:03:00,411 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-09 18:03:00,411 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-09 18:03:00,477 [INFO] Epochs count to train for 20, entering the training loop now
2025-01-09 21:21:48,507 [INFO] AlternatingLeastSquares algorithm running just ends. Exiting the run method... 
2025-01-09 21:21:48,587 [INFO] Checkpoint successfully saved at 20250109-212148_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10
2025-01-09 21:21:48,589 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-10 04:32:12,975 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-10 04:44:37,233 [INFO] Successfully indexed 32000204 lines from ./ml-32m/ratings.csv
2025-01-10 22:29:13,567 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-10 22:29:22,435 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-10 22:29:22,436 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-10 22:29:28,447 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-10 22:29:28,448 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-10 22:29:28,472 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-10 22:33:56,068 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-10 22:33:56,070 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-10 22:33:56,072 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:28:29,296 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 00:28:29,298 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:28:29,302 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:28:29,303 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:28:29,304 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:28:29,305 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:28:59,296 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': array([[ 0.66803859, -0.42017319,  1.79821248, ...,  2.01660122,
         0.00609515, -0.18994888],
       [-0.72676003, -0.97292564, -0.83542837, ..., -0.82822931,
        -0.21256158, -0.88999392],
       [-0.35849483,  0.52115392, -0.18519657, ..., -0.22866128,
         0.32431674, -0.91523274],
       ...,
       [ 1.1906259 ,  0.90197813,  0.84796976, ..., -0.06321017,
         0.4720177 , -0.15883818],
       [ 0.0742606 ,  0.27838817,  0.05924231, ..., -0.31611786,
        -0.26801993, -0.21589841],
       [ 0.53660388,  0.41992396, -0.2110134 , ..., -0.55068589,
         0.07160081,  0.11306214]]), 'item_factors': array([[-0.14566181, -0.22035893, -0.03858645, ...,  0.03635075,
        -0.04661084, -0.35857518],
       [ 0.69254094,  0.15864638, -0.07112142, ..., -0.52517401,
        -0.87689369,  0.29035806],
       [ 0.39030134,  0.80981618, -0.58111932, ..., -0.30118685,
        -0.23282532,  0.0666118 ],
       ...,
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987],
       [-0.11818416, -0.24837623,  0.06046458, ..., -0.19333925,
         0.14869257, -0.15013229],
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987]]), 'user_biases': array([3.08754976, 3.01240664, 3.23461301, ..., 2.83711568, 2.87175202,
       0.95061821]), 'item_biases': array([1.27981379, 0.32527807, 0.57628962, ..., 0.27130104, 0.21596027,
       0.27130104]), 'loss_train': [np.float64(-34790.247387690426), np.float64(-30434.39207322495), np.float64(-28505.575660181872), np.float64(-27424.112994930787), np.float64(-26727.813654206257), np.float64(-26234.007200814354), np.float64(-25857.7024917051), np.float64(-25558.45718760865), np.float64(-25312.034144288424), np.float64(-25097.513685063554), np.float64(-24912.099356707004), np.float64(-24742.018234728766), np.float64(-24591.164717324675), np.float64(-24451.697140696135), np.float64(-24323.532051402428), np.float64(-24203.383900366294), np.float64(-24092.149706656928), np.float64(-23987.665251744755), np.float64(-23890.889744707052), np.float64(-23797.734785464134)], 'loss_test': [np.float64(-18812.01782507389), np.float64(-18305.892795243322), np.float64(-17715.54452900091), np.float64(-17290.943863090975), np.float64(-16977.08743739604), np.float64(-16729.860522233954), np.float64(-16525.246901822557), np.float64(-16349.590246261288), np.float64(-16193.605258919142), np.float64(-16051.039319689984), np.float64(-15919.824349776854), np.float64(-15795.882817154961), np.float64(-15680.564161398044), np.float64(-15571.540907498143), np.float64(-15467.893190343388), np.float64(-15369.532589626957), np.float64(-15276.000807937233), np.float64(-15187.407706252248), np.float64(-15103.015784152238), np.float64(-15022.766807914024)], 'rmse_train': [np.float64(0.7817565668688028), np.float64(0.7125512059770251), np.float64(0.6844722824835088), np.float64(0.6698668250540903), np.float64(0.6610975326269364), np.float64(0.6553825784543453), np.float64(0.651415832226618), np.float64(0.6485747867188625), np.float64(0.6465056805788431), np.float64(0.6448762943923197), np.float64(0.6436471484406419), np.float64(0.6425864792755058), np.float64(0.6417701355710825), np.float64(0.6410719948573932), np.float64(0.6405027732977879), np.float64(0.6400018776341362), np.float64(0.6395956598647982), np.float64(0.6392455360020323), np.float64(0.6389833517488067), np.float64(0.6387279301427903)], 'rmse_test': [np.float64(0.9180982555504594), np.float64(0.9025350279647296), np.float64(0.8897600492808809), np.float64(0.8822266177399684), np.float64(0.87745922670067), np.float64(0.8743754019480581), np.float64(0.8723471690357081), np.float64(0.8709714292978358), np.float64(0.870016027268531), np.float64(0.8693189703667411), np.float64(0.8687962171638547), np.float64(0.8683142148018147), np.float64(0.8679479312666939), np.float64(0.8676401375120059), np.float64(0.8673732183619255), np.float64(0.8671517575250811), np.float64(0.8669748652488206), np.float64(0.8668594204101165), np.float64(0.8668011541907379), np.float64(0.8667931235127327)]}
2025-01-11 00:28:59,299 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:28:59,302 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:28:59,304 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:28:59,305 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:28:59,307 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:29:26,345 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': array([[ 0.66803859, -0.42017319,  1.79821248, ...,  2.01660122,
         0.00609515, -0.18994888],
       [-0.72676003, -0.97292564, -0.83542837, ..., -0.82822931,
        -0.21256158, -0.88999392],
       [-0.35849483,  0.52115392, -0.18519657, ..., -0.22866128,
         0.32431674, -0.91523274],
       ...,
       [ 1.1906259 ,  0.90197813,  0.84796976, ..., -0.06321017,
         0.4720177 , -0.15883818],
       [ 0.0742606 ,  0.27838817,  0.05924231, ..., -0.31611786,
        -0.26801993, -0.21589841],
       [ 0.53660388,  0.41992396, -0.2110134 , ..., -0.55068589,
         0.07160081,  0.11306214]]), 'item_factors': array([[-0.14566181, -0.22035893, -0.03858645, ...,  0.03635075,
        -0.04661084, -0.35857518],
       [ 0.69254094,  0.15864638, -0.07112142, ..., -0.52517401,
        -0.87689369,  0.29035806],
       [ 0.39030134,  0.80981618, -0.58111932, ..., -0.30118685,
        -0.23282532,  0.0666118 ],
       ...,
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987],
       [-0.11818416, -0.24837623,  0.06046458, ..., -0.19333925,
         0.14869257, -0.15013229],
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987]]), 'user_biases': array([3.08754976, 3.01240664, 3.23461301, ..., 2.83711568, 2.87175202,
       0.95061821]), 'item_biases': array([1.27981379, 0.32527807, 0.57628962, ..., 0.27130104, 0.21596027,
       0.27130104]), 'loss_train': [np.float64(-34790.247387690426), np.float64(-30434.39207322495), np.float64(-28505.575660181872), np.float64(-27424.112994930787), np.float64(-26727.813654206257), np.float64(-26234.007200814354), np.float64(-25857.7024917051), np.float64(-25558.45718760865), np.float64(-25312.034144288424), np.float64(-25097.513685063554), np.float64(-24912.099356707004), np.float64(-24742.018234728766), np.float64(-24591.164717324675), np.float64(-24451.697140696135), np.float64(-24323.532051402428), np.float64(-24203.383900366294), np.float64(-24092.149706656928), np.float64(-23987.665251744755), np.float64(-23890.889744707052), np.float64(-23797.734785464134)], 'loss_test': [np.float64(-18812.01782507389), np.float64(-18305.892795243322), np.float64(-17715.54452900091), np.float64(-17290.943863090975), np.float64(-16977.08743739604), np.float64(-16729.860522233954), np.float64(-16525.246901822557), np.float64(-16349.590246261288), np.float64(-16193.605258919142), np.float64(-16051.039319689984), np.float64(-15919.824349776854), np.float64(-15795.882817154961), np.float64(-15680.564161398044), np.float64(-15571.540907498143), np.float64(-15467.893190343388), np.float64(-15369.532589626957), np.float64(-15276.000807937233), np.float64(-15187.407706252248), np.float64(-15103.015784152238), np.float64(-15022.766807914024)], 'rmse_train': [np.float64(0.7817565668688028), np.float64(0.7125512059770251), np.float64(0.6844722824835088), np.float64(0.6698668250540903), np.float64(0.6610975326269364), np.float64(0.6553825784543453), np.float64(0.651415832226618), np.float64(0.6485747867188625), np.float64(0.6465056805788431), np.float64(0.6448762943923197), np.float64(0.6436471484406419), np.float64(0.6425864792755058), np.float64(0.6417701355710825), np.float64(0.6410719948573932), np.float64(0.6405027732977879), np.float64(0.6400018776341362), np.float64(0.6395956598647982), np.float64(0.6392455360020323), np.float64(0.6389833517488067), np.float64(0.6387279301427903)], 'rmse_test': [np.float64(0.9180982555504594), np.float64(0.9025350279647296), np.float64(0.8897600492808809), np.float64(0.8822266177399684), np.float64(0.87745922670067), np.float64(0.8743754019480581), np.float64(0.8723471690357081), np.float64(0.8709714292978358), np.float64(0.870016027268531), np.float64(0.8693189703667411), np.float64(0.8687962171638547), np.float64(0.8683142148018147), np.float64(0.8679479312666939), np.float64(0.8676401375120059), np.float64(0.8673732183619255), np.float64(0.8671517575250811), np.float64(0.8669748652488206), np.float64(0.8668594204101165), np.float64(0.8668011541907379), np.float64(0.8667931235127327)]}
2025-01-11 00:29:26,348 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:29:26,356 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:29:26,357 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:29:26,358 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:29:26,360 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:29:37,421 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': array([[ 0.66803859, -0.42017319,  1.79821248, ...,  2.01660122,
         0.00609515, -0.18994888],
       [-0.72676003, -0.97292564, -0.83542837, ..., -0.82822931,
        -0.21256158, -0.88999392],
       [-0.35849483,  0.52115392, -0.18519657, ..., -0.22866128,
         0.32431674, -0.91523274],
       ...,
       [ 1.1906259 ,  0.90197813,  0.84796976, ..., -0.06321017,
         0.4720177 , -0.15883818],
       [ 0.0742606 ,  0.27838817,  0.05924231, ..., -0.31611786,
        -0.26801993, -0.21589841],
       [ 0.53660388,  0.41992396, -0.2110134 , ..., -0.55068589,
         0.07160081,  0.11306214]]), 'item_factors': array([[-0.14566181, -0.22035893, -0.03858645, ...,  0.03635075,
        -0.04661084, -0.35857518],
       [ 0.69254094,  0.15864638, -0.07112142, ..., -0.52517401,
        -0.87689369,  0.29035806],
       [ 0.39030134,  0.80981618, -0.58111932, ..., -0.30118685,
        -0.23282532,  0.0666118 ],
       ...,
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987],
       [-0.11818416, -0.24837623,  0.06046458, ..., -0.19333925,
         0.14869257, -0.15013229],
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987]]), 'user_biases': array([3.08754976, 3.01240664, 3.23461301, ..., 2.83711568, 2.87175202,
       0.95061821]), 'item_biases': array([1.27981379, 0.32527807, 0.57628962, ..., 0.27130104, 0.21596027,
       0.27130104]), 'loss_train': [np.float64(-34790.247387690426), np.float64(-30434.39207322495), np.float64(-28505.575660181872), np.float64(-27424.112994930787), np.float64(-26727.813654206257), np.float64(-26234.007200814354), np.float64(-25857.7024917051), np.float64(-25558.45718760865), np.float64(-25312.034144288424), np.float64(-25097.513685063554), np.float64(-24912.099356707004), np.float64(-24742.018234728766), np.float64(-24591.164717324675), np.float64(-24451.697140696135), np.float64(-24323.532051402428), np.float64(-24203.383900366294), np.float64(-24092.149706656928), np.float64(-23987.665251744755), np.float64(-23890.889744707052), np.float64(-23797.734785464134)], 'loss_test': [np.float64(-18812.01782507389), np.float64(-18305.892795243322), np.float64(-17715.54452900091), np.float64(-17290.943863090975), np.float64(-16977.08743739604), np.float64(-16729.860522233954), np.float64(-16525.246901822557), np.float64(-16349.590246261288), np.float64(-16193.605258919142), np.float64(-16051.039319689984), np.float64(-15919.824349776854), np.float64(-15795.882817154961), np.float64(-15680.564161398044), np.float64(-15571.540907498143), np.float64(-15467.893190343388), np.float64(-15369.532589626957), np.float64(-15276.000807937233), np.float64(-15187.407706252248), np.float64(-15103.015784152238), np.float64(-15022.766807914024)], 'rmse_train': [np.float64(0.7817565668688028), np.float64(0.7125512059770251), np.float64(0.6844722824835088), np.float64(0.6698668250540903), np.float64(0.6610975326269364), np.float64(0.6553825784543453), np.float64(0.651415832226618), np.float64(0.6485747867188625), np.float64(0.6465056805788431), np.float64(0.6448762943923197), np.float64(0.6436471484406419), np.float64(0.6425864792755058), np.float64(0.6417701355710825), np.float64(0.6410719948573932), np.float64(0.6405027732977879), np.float64(0.6400018776341362), np.float64(0.6395956598647982), np.float64(0.6392455360020323), np.float64(0.6389833517488067), np.float64(0.6387279301427903)], 'rmse_test': [np.float64(0.9180982555504594), np.float64(0.9025350279647296), np.float64(0.8897600492808809), np.float64(0.8822266177399684), np.float64(0.87745922670067), np.float64(0.8743754019480581), np.float64(0.8723471690357081), np.float64(0.8709714292978358), np.float64(0.870016027268531), np.float64(0.8693189703667411), np.float64(0.8687962171638547), np.float64(0.8683142148018147), np.float64(0.8679479312666939), np.float64(0.8676401375120059), np.float64(0.8673732183619255), np.float64(0.8671517575250811), np.float64(0.8669748652488206), np.float64(0.8668594204101165), np.float64(0.8668011541907379), np.float64(0.8667931235127327)]}
2025-01-11 00:29:37,426 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:29:37,431 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:29:37,432 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:29:37,434 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:29:37,437 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:29:47,513 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': array([[ 0.66803859, -0.42017319,  1.79821248, ...,  2.01660122,
         0.00609515, -0.18994888],
       [-0.72676003, -0.97292564, -0.83542837, ..., -0.82822931,
        -0.21256158, -0.88999392],
       [-0.35849483,  0.52115392, -0.18519657, ..., -0.22866128,
         0.32431674, -0.91523274],
       ...,
       [ 1.1906259 ,  0.90197813,  0.84796976, ..., -0.06321017,
         0.4720177 , -0.15883818],
       [ 0.0742606 ,  0.27838817,  0.05924231, ..., -0.31611786,
        -0.26801993, -0.21589841],
       [ 0.53660388,  0.41992396, -0.2110134 , ..., -0.55068589,
         0.07160081,  0.11306214]]), 'item_factors': array([[-0.14566181, -0.22035893, -0.03858645, ...,  0.03635075,
        -0.04661084, -0.35857518],
       [ 0.69254094,  0.15864638, -0.07112142, ..., -0.52517401,
        -0.87689369,  0.29035806],
       [ 0.39030134,  0.80981618, -0.58111932, ..., -0.30118685,
        -0.23282532,  0.0666118 ],
       ...,
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987],
       [-0.11818416, -0.24837623,  0.06046458, ..., -0.19333925,
         0.14869257, -0.15013229],
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987]]), 'user_biases': array([3.08754976, 3.01240664, 3.23461301, ..., 2.83711568, 2.87175202,
       0.95061821]), 'item_biases': array([1.27981379, 0.32527807, 0.57628962, ..., 0.27130104, 0.21596027,
       0.27130104]), 'loss_train': [np.float64(-34790.247387690426), np.float64(-30434.39207322495), np.float64(-28505.575660181872), np.float64(-27424.112994930787), np.float64(-26727.813654206257), np.float64(-26234.007200814354), np.float64(-25857.7024917051), np.float64(-25558.45718760865), np.float64(-25312.034144288424), np.float64(-25097.513685063554), np.float64(-24912.099356707004), np.float64(-24742.018234728766), np.float64(-24591.164717324675), np.float64(-24451.697140696135), np.float64(-24323.532051402428), np.float64(-24203.383900366294), np.float64(-24092.149706656928), np.float64(-23987.665251744755), np.float64(-23890.889744707052), np.float64(-23797.734785464134)], 'loss_test': [np.float64(-18812.01782507389), np.float64(-18305.892795243322), np.float64(-17715.54452900091), np.float64(-17290.943863090975), np.float64(-16977.08743739604), np.float64(-16729.860522233954), np.float64(-16525.246901822557), np.float64(-16349.590246261288), np.float64(-16193.605258919142), np.float64(-16051.039319689984), np.float64(-15919.824349776854), np.float64(-15795.882817154961), np.float64(-15680.564161398044), np.float64(-15571.540907498143), np.float64(-15467.893190343388), np.float64(-15369.532589626957), np.float64(-15276.000807937233), np.float64(-15187.407706252248), np.float64(-15103.015784152238), np.float64(-15022.766807914024)], 'rmse_train': [np.float64(0.7817565668688028), np.float64(0.7125512059770251), np.float64(0.6844722824835088), np.float64(0.6698668250540903), np.float64(0.6610975326269364), np.float64(0.6553825784543453), np.float64(0.651415832226618), np.float64(0.6485747867188625), np.float64(0.6465056805788431), np.float64(0.6448762943923197), np.float64(0.6436471484406419), np.float64(0.6425864792755058), np.float64(0.6417701355710825), np.float64(0.6410719948573932), np.float64(0.6405027732977879), np.float64(0.6400018776341362), np.float64(0.6395956598647982), np.float64(0.6392455360020323), np.float64(0.6389833517488067), np.float64(0.6387279301427903)], 'rmse_test': [np.float64(0.9180982555504594), np.float64(0.9025350279647296), np.float64(0.8897600492808809), np.float64(0.8822266177399684), np.float64(0.87745922670067), np.float64(0.8743754019480581), np.float64(0.8723471690357081), np.float64(0.8709714292978358), np.float64(0.870016027268531), np.float64(0.8693189703667411), np.float64(0.8687962171638547), np.float64(0.8683142148018147), np.float64(0.8679479312666939), np.float64(0.8676401375120059), np.float64(0.8673732183619255), np.float64(0.8671517575250811), np.float64(0.8669748652488206), np.float64(0.8668594204101165), np.float64(0.8668011541907379), np.float64(0.8667931235127327)]}
2025-01-11 00:29:47,516 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:29:47,526 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:29:47,530 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:29:47,534 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:29:47,536 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:30:12,394 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:30:22,040 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 00:30:22,041 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 00:33:30,689 [DEBUG] matplotlib data path: /home/hjisaac/.cache/pypoetry/virtualenvs/recommender-system-uSlwvUxw-py3.10/lib/python3.10/site-packages/matplotlib/mpl-data
2025-01-11 00:33:30,699 [DEBUG] CONFIGDIR=/home/hjisaac/.config/matplotlib
2025-01-11 00:33:30,722 [DEBUG] interactive is False
2025-01-11 00:33:30,723 [DEBUG] platform is linux
2025-01-11 00:33:30,840 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 00:33:30,847 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 00:34:27,527 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:34:37,164 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 00:34:37,165 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 00:35:26,578 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 00:35:26,581 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:35:26,588 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:47:53,323 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 00:47:53,335 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 00:47:54,127 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:48:04,010 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 00:48:04,010 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 00:48:36,240 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 00:48:36,249 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 00:49:30,933 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:49:45,764 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 00:49:45,765 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 00:51:50,809 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:52:03,152 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 00:52:03,152 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 00:52:22,469 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 00:52:22,479 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 00:52:22,916 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:52:42,766 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 00:52:42,766 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 00:52:44,818 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 00:52:44,818 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:52:44,832 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:53:30,781 [ERROR] State that is being loaded does not have `feature_factors`, so cannot run {self.__class__.__name__} algorithm with feature included, exiting...
2025-01-11 00:53:30,782 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:53:30,782 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 00:53:30,782 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:53:30,783 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:55:24,250 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 00:55:24,259 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 00:55:24,676 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:55:47,045 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 00:55:47,046 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:55:47,050 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:55:47,050 [ERROR] State that is being loaded does not have `feature_factors`, so cannot run {self.__class__.__name__} algorithm with feature included, exiting...
2025-01-11 00:55:47,051 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:55:47,051 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 00:55:47,051 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:55:47,051 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:56:19,663 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': array([[ 0.66803859, -0.42017319,  1.79821248, ...,  2.01660122,
         0.00609515, -0.18994888],
       [-0.72676003, -0.97292564, -0.83542837, ..., -0.82822931,
        -0.21256158, -0.88999392],
       [-0.35849483,  0.52115392, -0.18519657, ..., -0.22866128,
         0.32431674, -0.91523274],
       ...,
       [ 1.1906259 ,  0.90197813,  0.84796976, ..., -0.06321017,
         0.4720177 , -0.15883818],
       [ 0.0742606 ,  0.27838817,  0.05924231, ..., -0.31611786,
        -0.26801993, -0.21589841],
       [ 0.53660388,  0.41992396, -0.2110134 , ..., -0.55068589,
         0.07160081,  0.11306214]]), 'item_factors': array([[-0.14566181, -0.22035893, -0.03858645, ...,  0.03635075,
        -0.04661084, -0.35857518],
       [ 0.69254094,  0.15864638, -0.07112142, ..., -0.52517401,
        -0.87689369,  0.29035806],
       [ 0.39030134,  0.80981618, -0.58111932, ..., -0.30118685,
        -0.23282532,  0.0666118 ],
       ...,
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987],
       [-0.11818416, -0.24837623,  0.06046458, ..., -0.19333925,
         0.14869257, -0.15013229],
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987]]), 'user_biases': array([3.08754976, 3.01240664, 3.23461301, ..., 2.83711568, 2.87175202,
       0.95061821]), 'item_biases': array([1.27981379, 0.32527807, 0.57628962, ..., 0.27130104, 0.21596027,
       0.27130104]), 'feature_factors': None, 'loss_train': [np.float64(-34790.247387690426), np.float64(-30434.39207322495), np.float64(-28505.575660181872), np.float64(-27424.112994930787), np.float64(-26727.813654206257), np.float64(-26234.007200814354), np.float64(-25857.7024917051), np.float64(-25558.45718760865), np.float64(-25312.034144288424), np.float64(-25097.513685063554), np.float64(-24912.099356707004), np.float64(-24742.018234728766), np.float64(-24591.164717324675), np.float64(-24451.697140696135), np.float64(-24323.532051402428), np.float64(-24203.383900366294), np.float64(-24092.149706656928), np.float64(-23987.665251744755), np.float64(-23890.889744707052), np.float64(-23797.734785464134)], 'loss_test': [np.float64(-18812.01782507389), np.float64(-18305.892795243322), np.float64(-17715.54452900091), np.float64(-17290.943863090975), np.float64(-16977.08743739604), np.float64(-16729.860522233954), np.float64(-16525.246901822557), np.float64(-16349.590246261288), np.float64(-16193.605258919142), np.float64(-16051.039319689984), np.float64(-15919.824349776854), np.float64(-15795.882817154961), np.float64(-15680.564161398044), np.float64(-15571.540907498143), np.float64(-15467.893190343388), np.float64(-15369.532589626957), np.float64(-15276.000807937233), np.float64(-15187.407706252248), np.float64(-15103.015784152238), np.float64(-15022.766807914024)], 'rmse_train': [np.float64(0.7817565668688028), np.float64(0.7125512059770251), np.float64(0.6844722824835088), np.float64(0.6698668250540903), np.float64(0.6610975326269364), np.float64(0.6553825784543453), np.float64(0.651415832226618), np.float64(0.6485747867188625), np.float64(0.6465056805788431), np.float64(0.6448762943923197), np.float64(0.6436471484406419), np.float64(0.6425864792755058), np.float64(0.6417701355710825), np.float64(0.6410719948573932), np.float64(0.6405027732977879), np.float64(0.6400018776341362), np.float64(0.6395956598647982), np.float64(0.6392455360020323), np.float64(0.6389833517488067), np.float64(0.6387279301427903)], 'rmse_test': [np.float64(0.9180982555504594), np.float64(0.9025350279647296), np.float64(0.8897600492808809), np.float64(0.8822266177399684), np.float64(0.87745922670067), np.float64(0.8743754019480581), np.float64(0.8723471690357081), np.float64(0.8709714292978358), np.float64(0.870016027268531), np.float64(0.8693189703667411), np.float64(0.8687962171638547), np.float64(0.8683142148018147), np.float64(0.8679479312666939), np.float64(0.8676401375120059), np.float64(0.8673732183619255), np.float64(0.8671517575250811), np.float64(0.8669748652488206), np.float64(0.8668594204101165), np.float64(0.8668011541907379), np.float64(0.8667931235127327)]}
2025-01-11 00:56:19,664 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:56:19,665 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:56:19,665 [ERROR] State that is being loaded does not have `feature_factors`, so cannot run {self.__class__.__name__} algorithm with feature included, exiting...
2025-01-11 00:56:19,666 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:56:19,666 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 00:56:19,666 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:56:19,666 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:56:43,192 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': array([[ 0.66803859, -0.42017319,  1.79821248, ...,  2.01660122,
         0.00609515, -0.18994888],
       [-0.72676003, -0.97292564, -0.83542837, ..., -0.82822931,
        -0.21256158, -0.88999392],
       [-0.35849483,  0.52115392, -0.18519657, ..., -0.22866128,
         0.32431674, -0.91523274],
       ...,
       [ 1.1906259 ,  0.90197813,  0.84796976, ..., -0.06321017,
         0.4720177 , -0.15883818],
       [ 0.0742606 ,  0.27838817,  0.05924231, ..., -0.31611786,
        -0.26801993, -0.21589841],
       [ 0.53660388,  0.41992396, -0.2110134 , ..., -0.55068589,
         0.07160081,  0.11306214]]), 'item_factors': array([[-0.14566181, -0.22035893, -0.03858645, ...,  0.03635075,
        -0.04661084, -0.35857518],
       [ 0.69254094,  0.15864638, -0.07112142, ..., -0.52517401,
        -0.87689369,  0.29035806],
       [ 0.39030134,  0.80981618, -0.58111932, ..., -0.30118685,
        -0.23282532,  0.0666118 ],
       ...,
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987],
       [-0.11818416, -0.24837623,  0.06046458, ..., -0.19333925,
         0.14869257, -0.15013229],
       [-0.15228376, -0.32004006,  0.07791038, ..., -0.2491233 ,
         0.19159474, -0.19344987]]), 'user_biases': array([3.08754976, 3.01240664, 3.23461301, ..., 2.83711568, 2.87175202,
       0.95061821]), 'item_biases': array([1.27981379, 0.32527807, 0.57628962, ..., 0.27130104, 0.21596027,
       0.27130104]), 'feature_factors': None, 'loss_train': [np.float64(-34790.247387690426), np.float64(-30434.39207322495), np.float64(-28505.575660181872), np.float64(-27424.112994930787), np.float64(-26727.813654206257), np.float64(-26234.007200814354), np.float64(-25857.7024917051), np.float64(-25558.45718760865), np.float64(-25312.034144288424), np.float64(-25097.513685063554), np.float64(-24912.099356707004), np.float64(-24742.018234728766), np.float64(-24591.164717324675), np.float64(-24451.697140696135), np.float64(-24323.532051402428), np.float64(-24203.383900366294), np.float64(-24092.149706656928), np.float64(-23987.665251744755), np.float64(-23890.889744707052), np.float64(-23797.734785464134)], 'loss_test': [np.float64(-18812.01782507389), np.float64(-18305.892795243322), np.float64(-17715.54452900091), np.float64(-17290.943863090975), np.float64(-16977.08743739604), np.float64(-16729.860522233954), np.float64(-16525.246901822557), np.float64(-16349.590246261288), np.float64(-16193.605258919142), np.float64(-16051.039319689984), np.float64(-15919.824349776854), np.float64(-15795.882817154961), np.float64(-15680.564161398044), np.float64(-15571.540907498143), np.float64(-15467.893190343388), np.float64(-15369.532589626957), np.float64(-15276.000807937233), np.float64(-15187.407706252248), np.float64(-15103.015784152238), np.float64(-15022.766807914024)], 'rmse_train': [np.float64(0.7817565668688028), np.float64(0.7125512059770251), np.float64(0.6844722824835088), np.float64(0.6698668250540903), np.float64(0.6610975326269364), np.float64(0.6553825784543453), np.float64(0.651415832226618), np.float64(0.6485747867188625), np.float64(0.6465056805788431), np.float64(0.6448762943923197), np.float64(0.6436471484406419), np.float64(0.6425864792755058), np.float64(0.6417701355710825), np.float64(0.6410719948573932), np.float64(0.6405027732977879), np.float64(0.6400018776341362), np.float64(0.6395956598647982), np.float64(0.6392455360020323), np.float64(0.6389833517488067), np.float64(0.6387279301427903)], 'rmse_test': [np.float64(0.9180982555504594), np.float64(0.9025350279647296), np.float64(0.8897600492808809), np.float64(0.8822266177399684), np.float64(0.87745922670067), np.float64(0.8743754019480581), np.float64(0.8723471690357081), np.float64(0.8709714292978358), np.float64(0.870016027268531), np.float64(0.8693189703667411), np.float64(0.8687962171638547), np.float64(0.8683142148018147), np.float64(0.8679479312666939), np.float64(0.8676401375120059), np.float64(0.8673732183619255), np.float64(0.8671517575250811), np.float64(0.8669748652488206), np.float64(0.8668594204101165), np.float64(0.8668011541907379), np.float64(0.8667931235127327)]}
2025-01-11 00:56:43,192 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:56:43,194 [INFO] Checkpoint ./artifacts/checkpoints/als/1000000/20250109-175920_lambda0.1_gamma0.1_tau0.1_n_epochs20_n_factors10.pkl loaded with success
2025-01-11 00:56:43,194 [ERROR] State that is being loaded does not have `feature_factors`, so cannot run {self.__class__.__name__} algorithm with feature included, exiting...
2025-01-11 00:56:43,194 [INFO] All factors and biases are already provided, so no initialization is needed.
2025-01-11 00:56:43,194 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 00:56:43,194 [ERROR] Cannot train the model more because hyperparameter 'hyper_n_epochs' (20) is already greater or equal to the final number of epochs wanted which is 20. Please check the value of 'hyper_n_epochs' and adjust accordingly. Exiting...
2025-01-11 00:56:43,194 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 00:57:11,827 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 20, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 00:57:11,827 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:57:11,828 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 00:57:11,838 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 00:57:11,838 [INFO] Epochs count to train for 20, entering the training loop now...
2025-01-11 00:58:29,103 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 00:58:29,112 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 00:58:29,524 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 00:58:50,167 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 00:58:50,168 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 00:58:52,258 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 00:58:52,258 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 00:59:07,350 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 00:59:07,358 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 00:59:07,358 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:00:14,391 [DEBUG] matplotlib data path: /home/hjisaac/.cache/pypoetry/virtualenvs/recommender-system-uSlwvUxw-py3.10/lib/python3.10/site-packages/matplotlib/mpl-data
2025-01-11 01:00:14,400 [DEBUG] CONFIGDIR=/home/hjisaac/.config/matplotlib
2025-01-11 01:00:14,417 [DEBUG] interactive is False
2025-01-11 01:00:14,418 [DEBUG] platform is linux
2025-01-11 01:00:14,512 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:00:14,522 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:00:36,462 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:00:36,471 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:00:36,848 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:00:55,367 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:00:55,367 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:00:57,145 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:00:57,145 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:00:57,147 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:00:57,154 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:00:57,154 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:02:26,397 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:02:26,406 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:02:26,782 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:02:45,097 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:02:45,097 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:02:46,905 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:02:46,905 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:02:46,907 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:02:46,915 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:02:46,915 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:03:33,912 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:03:41,479 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:03:41,479 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:10:42,569 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:10:42,578 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:10:42,949 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:11:02,110 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:11:02,110 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:11:03,932 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:11:03,932 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:11:03,934 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:11:03,941 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:11:03,941 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:11:43,023 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:11:43,032 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:11:43,399 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:12:03,111 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:12:03,112 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:12:05,052 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:12:05,052 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:12:05,054 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:12:05,062 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:12:05,062 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:13:21,289 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:13:21,299 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:13:21,701 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:13:41,982 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:13:41,982 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:13:43,819 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:13:43,820 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:13:43,821 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:13:43,829 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:13:43,829 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:32:49,169 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:32:49,179 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:32:49,550 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:33:08,735 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:33:08,735 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:33:10,575 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:33:10,575 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:33:46,776 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:33:46,784 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:33:47,226 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:34:06,868 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:34:06,868 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:34:08,700 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:34:08,700 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:35:27,754 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:35:27,764 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:35:28,136 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:35:47,883 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:35:47,883 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:35:49,674 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:35:49,674 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:36:10,006 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:36:10,016 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:36:10,016 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:39:20,918 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:39:20,928 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:39:21,309 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:39:40,707 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:39:40,708 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:39:42,562 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:39:42,562 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:39:42,579 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:39:42,586 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:39:42,586 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:42:01,955 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:42:01,964 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:42:02,345 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:42:20,680 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:42:20,680 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:42:22,477 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:42:22,477 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:42:22,479 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:42:22,487 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:42:22,487 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:43:48,582 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:43:48,591 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:43:48,969 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:44:07,070 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:44:07,070 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:44:08,880 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:44:08,880 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:44:08,882 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:44:08,889 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:44:08,889 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:45:12,494 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:45:12,503 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:45:12,929 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:45:31,988 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:45:31,988 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:45:33,768 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:45:33,769 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:45:33,770 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:45:33,777 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:45:33,777 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:51:59,312 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:51:59,323 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:51:59,728 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:52:20,060 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:52:20,061 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:52:21,864 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:52:21,864 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:52:21,866 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:52:21,873 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:52:21,873 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:56:43,297 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:56:43,306 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:56:43,675 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:57:02,043 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:57:02,043 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:57:03,818 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:57:03,818 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:57:03,820 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:57:03,827 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:57:03,827 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 01:59:08,762 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 01:59:08,773 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 01:59:09,151 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 01:59:28,594 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 01:59:28,594 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 01:59:30,448 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 01:59:30,448 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 01:59:30,449 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 01:59:30,457 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 01:59:30,457 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 02:01:10,164 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 02:01:18,301 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 02:01:18,302 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 02:01:21,869 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 02:01:21,884 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 02:01:22,367 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 02:01:41,115 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 02:01:41,115 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 02:01:42,899 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 02:01:42,899 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 02:01:42,901 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 02:01:42,908 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 02:01:42,908 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 02:48:00,950 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 02:48:08,859 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 02:48:08,859 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 02:50:06,141 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 02:50:14,312 [WARNING] The limit of lines (.i.e 1000000) to index has been reached. Exiting without loading the rest... 
2025-01-11 02:50:14,313 [INFO] Successfully indexed 1000000 lines from ./ml-32m/ratings.csv
2025-01-11 02:50:18,211 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 02:50:18,229 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 02:50:18,839 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 02:50:18,909 [WARNING] The limit of lines (.i.e 1000) to index has been reached. Exiting without loading the rest... 
2025-01-11 02:50:18,909 [INFO] Successfully indexed 1000 lines from ./ml-32m/ratings.csv
2025-01-11 02:50:20,767 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 02:50:20,768 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 02:50:20,769 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 02:50:20,770 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 02:50:20,770 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 02:51:39,151 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 02:51:39,160 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 02:51:39,559 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 02:51:39,612 [WARNING] The limit of lines (.i.e 1000) to index has been reached. Exiting without loading the rest... 
2025-01-11 02:51:39,612 [INFO] Successfully indexed 1000 lines from ./ml-32m/ratings.csv
2025-01-11 02:51:41,192 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 02:51:41,192 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 02:51:41,193 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 02:51:41,194 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 02:51:41,194 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 03:19:58,022 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 03:19:58,030 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 03:19:58,399 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 03:19:58,457 [WARNING] The limit of lines (.i.e 1000) to index has been reached. Exiting without loading the rest... 
2025-01-11 03:19:58,457 [INFO] Successfully indexed 1000 lines from ./ml-32m/ratings.csv
2025-01-11 03:20:00,036 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 03:20:00,036 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 03:20:00,038 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 03:20:00,039 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 03:20:00,039 [INFO] Epochs count to train for 2, entering the training loop now...
2025-01-11 03:24:59,586 [INFO] Successfully run AlternatingLeastSquares algorithm running till the end
2025-01-11 03:24:59,587 [DEBUG] Cleaning the AlternatingLeastSquares algorithm self maintained cache, and exiting...
2025-01-11 03:24:59,588 [INFO] Successfully built the recommender using AlternatingLeastSquares
2025-01-11 03:25:03,261 [DEBUG] CACHEDIR=/home/hjisaac/.cache/matplotlib
2025-01-11 03:25:03,271 [DEBUG] Using fontManager instance from /home/hjisaac/.cache/matplotlib/fontlist-v390.json
2025-01-11 03:25:04,094 [WARNING] The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether a given data point should be used as a training data or a test data.
2025-01-11 03:25:04,105 [WARNING] The limit of lines (.i.e 1000) to index has been reached. Exiting without loading the rest... 
2025-01-11 03:25:04,105 [INFO] Successfully indexed 1000 lines from ./ml-32m/ratings.csv
2025-01-11 03:25:05,983 [INFO] Starting the build of the recommender using AlternatingLeastSquares with the state {'hyper_lambda': 0.1, 'hyper_tau': 0.1, 'hyper_gamma': 0.1, 'hyper_n_epochs': 2, 'hyper_n_factors': 10, 'user_factors': None, 'item_factors': None, 'user_biases': None, 'item_biases': None, 'feature_factors': None, 'loss_train': [], 'loss_test': [], 'rmse_train': [], 'rmse_test': []}
2025-01-11 03:25:05,984 [INFO] Starting a model fitting using the backend AlternatingLeastSquares...
2025-01-11 03:25:05,984 [INFO] Initializing user and item's factors and biases, as none of them is provided.
2025-01-11 03:25:05,984 [INFO] About to start training with the `include_features` parameter set to True.
2025-01-11 03:25:05,984 [INFO] Epochs count to train for 2, entering the training loop now...
