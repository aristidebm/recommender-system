{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-30T23:08:29.379826Z",
     "start_time": "2024-12-30T23:08:29.372318Z"
    }
   },
   "source": [
    "from src.algorithms.alternating_least_squares import AlternatingLeastSquares\n",
    "from src.helpers.dataset_indexer import DatasetIndexer\n",
    "from src.helpers.checkpoint_manager import CheckpointManager\n",
    "from src.recommenders import CollaborativeFilteringRecommenderBuilder\n",
    "from src.backends import Backend\n",
    "\n",
    "from src.settings import settings"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "f514cb70517008ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T23:08:29.412290Z",
     "start_time": "2024-12-30T23:08:29.401888Z"
    }
   },
   "source": [
    "dataset_indexer = DatasetIndexer(\n",
    "    file_path=\"./ml-32m/ratings.csv\",\n",
    "    user_header=\"userId\",\n",
    "    item_header=\"movieId\",\n",
    "    rating_header=\"rating\",\n",
    "    limit=5000,\n",
    ")\n",
    "\n",
    "indexed_data = dataset_indexer.index(approximate_train_ratio=0.8)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.\n",
      "The limit of lines (.i.e 100) to index has been reached. Exiting without loading the rest... \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "db7f06b057e86e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T23:08:29.480170Z",
     "start_time": "2024-12-30T23:08:29.473225Z"
    }
   },
   "source": [
    "als_instance = AlternatingLeastSquares(\n",
    "    hyper_lambda=settings.als.HYPER_LAMBDA,\n",
    "    hyper_gamma=settings.als.HYPER_GAMMA,\n",
    "    hyper_tau=settings.als.HYPER_TAU,\n",
    "    hyper_n_epochs=settings.als.HYPER_N_EPOCH,\n",
    "    hyper_n_factors=settings.als.HYPER_N_FACTOR,\n",
    ")\n",
    "\n",
    "als_backend = Backend(\n",
    "    # Define the algorithm\n",
    "    algorithm=als_instance,\n",
    "    checkpoint_manager=CheckpointManager(\n",
    "        checkpoint_folder=settings.als.CHECKPOINT_FOLDER,\n",
    "    ),\n",
    "    resume_enabled=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T23:08:29.611799Z",
     "start_time": "2024-12-30T23:08:29.534946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recommender_builder = CollaborativeFilteringRecommenderBuilder(\n",
    "    backend=als_backend,\n",
    ")\n",
    "\n",
    "# This might take some moment before finishing\n",
    "recommender = recommender_builder.build(data=indexed_data)"
   ],
   "id": "a6088fcc1307ccc4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/4 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m recommender_builder \u001b[38;5;241m=\u001b[39m CollaborativeFilteringRecommenderBuilder(\n\u001b[1;32m      2\u001b[0m     backend\u001b[38;5;241m=\u001b[39mals_backend,\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# This might take some moment before finishing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m recommender \u001b[38;5;241m=\u001b[39m \u001b[43mrecommender_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexed_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/recommenders/__init__.py:43\u001b[0m, in \u001b[0;36mCollaborativeFilteringRecommenderBuilder.build\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     37\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting the build of the recommender using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting a model fitting using the backend \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 43\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully built the recommender using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Recommender(predictor\u001b[38;5;241m=\u001b[39mpredictor)\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/backends/__init__.py:25\u001b[0m, in \u001b[0;36mBackend.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resume:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# TODO:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# self.algorithm.set_state(self.checkpoint_manager.load())\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resume\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m checkpoint_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_checkpoint_name()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Save the current state of the training from the algorithm object\u001b[39;00m\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/algorithms/alternating_least_squares.py:517\u001b[0m, in \u001b[0;36mAlternatingLeastSquares.run\u001b[0;34m(self, data, resume)\u001b[0m\n\u001b[1;32m    512\u001b[0m loss_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(accumulated_squared_residual_test)\n\u001b[1;32m    514\u001b[0m rmse_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_rmse(\n\u001b[1;32m    515\u001b[0m     accumulated_squared_residual_train, residuals_count_train\n\u001b[1;32m    516\u001b[0m )\n\u001b[0;32m--> 517\u001b[0m rmse_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_rmse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulated_squared_residual_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresiduals_count_test\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs_loss_train\u001b[38;5;241m.\u001b[39mappend(loss_train)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs_loss_test\u001b[38;5;241m.\u001b[39mappend(loss_test)\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/algorithms/alternating_least_squares.py:389\u001b[0m, in \u001b[0;36mAlternatingLeastSquares._compute_rmse\u001b[0;34m(accumulated_squared_residual, residuals_count)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_rmse\u001b[39m(\n\u001b[1;32m    384\u001b[0m     accumulated_squared_residual: \u001b[38;5;28mfloat\u001b[39m, residuals_count: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m    385\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Returns the Root Mean Squared Error\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43maccumulated_squared_residual\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresiduals_count\u001b[49m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T23:08:29.740937021Z",
     "start_time": "2024-12-30T22:03:59.910856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction_input = [{\"rating\": 4}, \"movieId: 1\", \"userId: 1\"]\n",
    "recommender.recommend(prediction_input)"
   ],
   "id": "cef422cfbcaa8b63",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prediction_input \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovieId: 1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserId: 1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrecommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/recommenders/__init__.py:15\u001b[0m, in \u001b[0;36mRecommender.recommend\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mrender(predictions)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommending\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mrender(predictions))\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/helpers/predictor.py:8\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/algorithms/alternating_least_squares.py:61\u001b[0m, in \u001b[0;36mAlternatingLeastSquaresState.to_predictor.<locals>.predict\u001b[0;34m(user_ratings_data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(user_ratings_data: \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    Predict ratings for a user based on user and item factors and biases.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m        np.ndarray: Predicted ratings for all items.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     user_factor, user_bias \u001b[38;5;241m=\u001b[39m \u001b[43m_als\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_user_bias_and_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ratings_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# The order of the vectors in the matrix product matters\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# as they have the following shape respectively:\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# (`items_count`, hyper_n_factors) and (hyper_n_factors, 1)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Broadcasting is used for the biases additions.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(_als\u001b[38;5;241m.\u001b[39mitem_factors, user_factor) \u001b[38;5;241m+\u001b[39m user_bias \u001b[38;5;241m+\u001b[39m _als\u001b[38;5;241m.\u001b[39mitem_biases\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/algorithms/alternating_least_squares.py:342\u001b[0m, in \u001b[0;36mAlternatingLeastSquares.learn_user_bias_and_factor\u001b[0;34m(self, user_id, user_ratings_data)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn_user_bias_and_factor\u001b[39m(\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m, user_id: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, user_ratings_data: Optional[\u001b[38;5;28mlist\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    336\u001b[0m ):\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    Learn or compute the given user_id related bias and factor based on the\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    provided ratings data and the actual state of the item biases and factors.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learn_bias_and_factor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLearningTargetEnum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUSER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mratings_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_ratings_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI4Science/ml_at_scale/src/algorithms/alternating_least_squares.py:284\u001b[0m, in \u001b[0;36mAlternatingLeastSquares._learn_bias_and_factor\u001b[0;34m(self, target, target_id, ratings_data)\u001b[0m\n\u001b[1;32m    281\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# The old factor that we want to use in other to learn a new one\u001b[39;00m\n\u001b[1;32m    283\u001b[0m factor \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 284\u001b[0m     \u001b[43mtarget_factors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_id\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_factor_sample(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyper_n_factors)\n\u001b[1;32m    287\u001b[0m )\n\u001b[1;32m    288\u001b[0m ratings_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    289\u001b[0m _A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyper_n_factors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyper_n_factors))\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T23:08:29.741970349Z",
     "start_time": "2024-12-30T21:16:43.439977Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "298347782d68fe2f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender-system-uSlwvUxw-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
