{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-28T15:07:39.706483Z",
     "start_time": "2024-12-28T15:07:39.670055Z"
    }
   },
   "source": [
    "from src.algorithms.alternating_least_squares import AlternatingLeastSquares\n",
    "from src.helpers.dataset_indexer import DatasetIndexer\n",
    "from src.helpers.checkpoint_manager import CheckpointManager\n",
    "from src.recommenders import CollaborativeFilteringRecommenderBuilder\n",
    "from src.backends import Backend\n",
    "\n",
    "from src.settings import settings"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T15:07:53.687399Z",
     "start_time": "2024-12-28T15:07:53.432284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_indexer = DatasetIndexer(\n",
    "    file_path=\"./ml-32m/ratings.csv\",\n",
    "    user_header=\"userId\",\n",
    "    item_header=\"movieId\",\n",
    "    rating_header=\"rating\",\n",
    "    limit=10000,\n",
    ")\n",
    "\n",
    "indexed_data = dataset_indexer.index(approximate_train_ratio=0.8)"
   ],
   "id": "f514cb70517008ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current implementation does not split the data into train and test sets exactly with the provided ratio. We use the provided ratio as a probability for a Bernoulli distribution to know whether the data point should be used as a training data or a test data.\n",
      "Limit of lines (.i.e 10000) to index has been reached. Exiting without loading the rest... \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T15:07:55.869136Z",
     "start_time": "2024-12-28T15:07:55.853538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alternating_least_squares = AlternatingLeastSquares(\n",
    "    hyper_lambda=settings.als.HYPER_LAMBDA,\n",
    "    hyper_gamma=settings.als.HYPER_GAMMA,\n",
    "    hyper_tau=settings.als.HYPER_TAU,\n",
    "    hyper_n_epochs=settings.als.HYPER_N_EPOCH,\n",
    "    hyper_n_factors=settings.als.HYPER_N_FACTOR,\n",
    ")\n",
    "\n",
    "als_backend = Backend(\n",
    "    # Define the algorithm\n",
    "    algorithm=alternating_least_squares,\n",
    "    checkpoint_manager=CheckpointManager(\n",
    "        checkpoint_folder=settings.als.CHECKPOINT_FOLDER,\n",
    "    ),\n",
    ")"
   ],
   "id": "db7f06b057e86e5c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T15:08:01.302721Z",
     "start_time": "2024-12-28T15:08:01.225313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recommender_builder = CollaborativeFilteringRecommenderBuilder(\n",
    "    backend=als_backend,\n",
    ")\n",
    "\n",
    "recommender = recommender_builder.build(data=indexed_data)\n",
    "\n",
    "# recommenders.recommend(None)"
   ],
   "id": "a6088fcc1307ccc4",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m recommender_builder \u001B[38;5;241m=\u001B[39m CollaborativeFilteringRecommenderBuilder(\n\u001B[1;32m      2\u001B[0m     backend\u001B[38;5;241m=\u001B[39mals_backend,\n\u001B[1;32m      3\u001B[0m )\n\u001B[0;32m----> 5\u001B[0m recommender \u001B[38;5;241m=\u001B[39m \u001B[43mrecommender_builder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindexed_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# recommender.recommend(None)\u001B[39;00m\n",
      "File \u001B[0;32m~/AI4Science/ml_at_scale/src/recommender/__init__.py:41\u001B[0m, in \u001B[0;36mCollaborativeFilteringRecommenderBuilder.build\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     35\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting the build of the recommender using \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39malgorithm\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     37\u001B[0m )\n\u001B[1;32m     38\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting a model fitting using the backend \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39malgorithm\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     40\u001B[0m )\n\u001B[0;32m---> 41\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully built the recommender using \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39malgorithm\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     44\u001B[0m )\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Recommender(predictor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39mpredictor)\n",
      "File \u001B[0;32m~/AI4Science/ml_at_scale/src/backends/__init__.py:29\u001B[0m, in \u001B[0;36mBackend.__call__\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malgorithm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexed_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# Save the current state of the training from the algorithm object\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;66;03m# self.checkpoint_manager.save(self.algorithm.state, self._instance_name)\u001B[39;00m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;66;03m# TODO: Clean this\u001B[39;00m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# self.checkpoint_manager.save(\u001B[39;00m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;66;03m#     {\"loss_test\": loss_test, \"loss_train\": loss_train}, self.__model_name\u001B[39;00m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[1;32m     36\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheckpoint successfully saved at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/AI4Science/ml_at_scale/src/algorithms/alternating_least_squares.py:335\u001B[0m, in \u001B[0;36mfit\u001B[0;34m(self, indexed_data)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_user_bias_and_factor\u001B[39m(\u001B[38;5;28mself\u001B[39m, user_id, user_ratings_data: \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    Side effect method that updates the given user's bias and latent factor\u001B[39;00m\n\u001B[0;32m--> 335\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    336\u001B[0m     user_factor, user_bias \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlearn_user_bias_and_factor(\n\u001B[1;32m    337\u001B[0m         user_id, user_ratings_data\n\u001B[1;32m    338\u001B[0m     )\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_biases[user_id] \u001B[38;5;241m=\u001B[39m user_bias\n",
      "File \u001B[0;32m~/AI4Science/ml_at_scale/src/algorithms/alternating_least_squares.py:92\u001B[0m, in \u001B[0;36m_initialize_factors_and_biases\u001B[0;34m(self, data_by_user_id__train, data_by_item_id__train)\u001B[0m\n\u001B[1;32m     73\u001B[0m @property\n\u001B[1;32m     74\u001B[0m def state(self) -> AlgorithmState:\n\u001B[1;32m     76\u001B[0m     return AlgorithmState(\n\u001B[1;32m     77\u001B[0m         {\n\u001B[1;32m     78\u001B[0m             \"hyper_lambda\": self.hyper_lambda,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     87\u001B[0m         }\n\u001B[1;32m     88\u001B[0m     )\n\u001B[1;32m     90\u001B[0m def _initialize_factors_and_biases(\n\u001B[1;32m     91\u001B[0m     self, data_by_user_id__train, data_by_item_id__train\n\u001B[0;32m---> 92\u001B[0m ):\n\u001B[1;32m     93\u001B[0m     users_count = len(data_by_user_id__train)\n\u001B[1;32m     94\u001B[0m     items_count = len(data_by_item_id__train)\n",
      "\u001B[0;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T15:07:40.010464854Z",
     "start_time": "2024-12-26T02:30:13.178608Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "298347782d68fe2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  numpy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 65\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMethod: \u001B[39m\u001B[38;5;124m\"\u001B[39m, method)\n\u001B[1;32m     64\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 65\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mline_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mline_limit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n\u001B[1;32m     67\u001B[0m results[method] \u001B[38;5;241m=\u001B[39m elapsed_time\n",
      "Cell \u001B[0;32mIn[23], line 22\u001B[0m, in \u001B[0;36mprocess_with_numpy\u001B[0;34m(file, line_limit)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_with_numpy\u001B[39m(file, line_limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     21\u001B[0m     to_process \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 22\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenfromtxt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(data):\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m line_limit \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m i \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m line_limit:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/recommender-system-uSlwvUxw-py3.10/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:2269\u001B[0m, in \u001B[0;36mgenfromtxt\u001B[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001B[0m\n\u001B[1;32m   2267\u001B[0m \u001B[38;5;66;03m# Parse each line\u001B[39;00m\n\u001B[1;32m   2268\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (i, line) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(itertools\u001B[38;5;241m.\u001B[39mchain([first_line, ], fhd)):\n\u001B[0;32m-> 2269\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43msplit_line\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2270\u001B[0m     nbvalues \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(values)\n\u001B[1;32m   2271\u001B[0m     \u001B[38;5;66;03m# Skip an empty line\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/recommender-system-uSlwvUxw-py3.10/lib/python3.10/site-packages/numpy/lib/_iotools.py:225\u001B[0m, in \u001B[0;36mLineSplitter.__call__\u001B[0;34m(self, line)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, line):\n\u001B[0;32m--> 225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handyman\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_decode_line\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/recommender-system-uSlwvUxw-py3.10/lib/python3.10/site-packages/numpy/lib/_iotools.py:201\u001B[0m, in \u001B[0;36mLineSplitter._delimited_splitter\u001B[0;34m(self, line)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomments \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    200\u001B[0m     line \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomments)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 201\u001B[0m line \u001B[38;5;241m=\u001B[39m \u001B[43mline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrip\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;130;43;01m\\r\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line:\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
